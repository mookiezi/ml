import re
import nltk
from nltk.corpus import words

nltk.download('words')
english_words = set(words.words())

# Custom words to filter out (add more as needed)
filter_words = {"candy", "lady", "pony", "sup", "nsfw", "nov", "im", "real", "girl", "fake", "zombie", "big", "more", "king"}

# **Verification Function**
def verify_words(word_list):
    for word in word_list:
        if word.lower() not in english_words:
            print(f"'{word}' NOT found in nltk.corpus.words")
        else:
            print(f"'{word}' FOUND in nltk.corpus.words")

verify_words(["lady", "real", "fake", "zombie", "big", "more", "king"])  # Check the words in question

def clean_and_format_names(input_filename, output_filename):
    """
    Reads names from a file, attempts to convert "fancy" unicode characters
    to their closest ASCII equivalents, removes other symbols and numbers,
    filters out English words and unwanted sequences, and removes single
    letter words.
    Splits names into individual words,
    encloses each word in quotes, joins them with ", ", and saves
    the result to a new file.  It also adds line breaks after every
    comma if the line exceeds 65 characters.

    Args:
        input_filename (str): The name of the input file (txt or csv).
        output_filename (str): The name of the output file.
    """

    def insert_linebreaks(text, max_line_length=65):
        words_in_line = text.split(',')
        current_line = ''
        result = []

        for word in words_in_line:
            word = word.strip()  # Remove leading/trailing spaces from each word
            if len(current_line + word) + (1 if current_line else 0) <= max_line_length:
                current_line += (',' if current_line else '') + word
            else:
                result.append(current_line + ',')
                current_line = word
        result.append(current_line + ',')
        return '\n'.join(result).replace('\n,', '\n')

    def replace_and_remove_chars(text):
        # Extended character mapping
        char_map = {
            'ð¿': 'L', 'ð’´': 'Y', 'ð’©': 'N',
            'ð–¦¹': '',  # Remove this symbol
            'ð”€': 'w', 'ð“¸': 'o', 'ð“µ': 'l', 'ð“¯': 'f', 'ð“°': 'g', 'ð“²': 'i', 'ð“»': 'r',
            'ð–œ': 'w',
            'Ê': 'Y', 'ð™¤': 'o', 'ð™': 'h', 'ð˜¢': 'a', 'ð—»': 'n',
            'ð–…': 'Z', 'ð–†': 'a', 'ð–ˆ': 'c', 'ð–': 'h',
            'ð•µ': 'J', 'ð–”': 'o', 'ð–': 'h', 'ð–†': 'a', 'ð–“': 'n', 'ð™¼': 'M', 'ðš˜': 'o', 'ðš—': 'n', 'ðšœ': 's', 'ðš': 't', 'ðšŽ': 'e', 'ðš›': 'r',
            'ð“’': 'C', 'ð’½': 'h', 'ð’¶': 'a', 'ð“ƒ': 'n', 'ð‘’': 'e',
            'ð•Ž': 'W',
            'ð”¸': 'A', 'ð”¹': 'B', 'ð—–': 'C', 'ð”»': 'D', 'ð”¼': 'E', 'ð”½': 'F', 'ð”¾': 'G', 'â„': 'H', 'ð•€': 'I', 'ð•': 'J', 'ð•‚': 'K', 'ð•ƒ': 'L', 'ð•„': 'M', 'â„•': 'N', 'ð•†': 'O', 'â„™': 'P', 'â„š': 'Q', 'â„': 'R', 'ð•Š': 'S', 'ð•‹': 'T', 'ð•Œ': 'U', 'ð•': 'V', 'ð•Ž': 'W', 'ð•': 'X', 'ð•': 'Y', 'â„¤': 'Z',
            'ð•’': 'a', 'ð•“': 'b', 'ð•”': 'c', 'ð••': 'd', 'ð•–': 'e', 'ð•—': 'f', 'ð•˜': 'g', 'ð•™': 'h', 'ð•š': 'i', 'ð•›': 'j', 'ð•œ': 'k', 'ð•': 'l', 'ð•ž': 'm', 'ð•Ÿ': 'n', 'ð• ': 'o', 'ð•¡': 'p', 'ð•¢': 'q', 'ð•£': 'r', 'ð•¤': 's', 'ð•¥': 't', 'ð•¦': 'u', 'ð•§': 'v', 'ð•¨': 'w', 'ð•©': 'x', 'ð•ª': 'y', 'ð•«': 'z',
            'Ã ': 'a', 'Ã¡': 'a', 'Ã¢': 'a', 'Ã¤': 'a',
            'Ã¨': 'e', 'Ã©': 'e', 'Ãª': 'e', 'Ã«': 'e',
            'Ã¬': 'i', 'Ã­': 'i', 'Ã®': 'i', 'Ã¯': 'i',
            'Ã²': 'o', 'Ã³': 'o', 'Ã´': 'o', 'Ã¶': 'o',
            'Ã¹': 'u', 'Ãº': 'u', 'Ã»': 'u', 'Ã¼': 'u',
            'Ã§': 'c', 'Ã±': 'n',
            'Å™': 'r', 'Ä…': 'a',
            'Å': 'o', 'Å«': 'u'
        }
        text = "".join(char_map.get(char, char) for char in text)

        # Specific removals using regex
        text = re.sub(r'ð“†', '', text)  # Remove frogs
        text = re.sub(r'á“šá˜á—¢', '', text)  # Remove cat face
        text = re.sub(r'[^\x00-\x7F]+', '', text)  # Remove all non-ASCII
        text = re.sub(r'[\u4e00-\u9fff]+', '', text) # Remove CJK characters
        text = re.sub(r'[\u0600-\u06FF]+', '', text) # Remove Arabic characters
        text = re.sub(r'ášºá›–áš¨áš¢á›–áš¾á›šáš¤á›—á›Ÿá›–', '', text) # Remove specific runes
        return text

    try:
        with open(input_filename, 'r', encoding='utf-8') as infile:
            all_names = infile.read().splitlines()
    except FileNotFoundError:
        print(f"Error: Input file '{input_filename}' not found.")
        return

    quoted_words = set()  # Use a set to track unique words
    for name in all_names:
        # Replace fancy characters and remove specific sequences
        name = replace_and_remove_chars(name)

        # Remove symbols and numbers
        cleaned_name = re.sub(r'[^\w\s]', '', name)
        cleaned_name = re.sub(r'\d+', '', cleaned_name)
        cleaned_name = cleaned_name.lower()

        # Remove leading spaces and spaces between single letters
        cleaned_name = cleaned_name.lstrip()
        cleaned_name = re.sub(r'(?<!\w)(\w)\s+(\w)(?!\w)', r'\1\2', cleaned_name)

        should_keep = True

        if cleaned_name in filter_words:
            should_keep = False
        elif cleaned_name in english_words:
            should_keep = False
        elif len(cleaned_name) <= 1:
            should_keep = False

        if should_keep:
            cleaned_words = cleaned_name.split()
            cleaned_name = "".join(cleaned_words)
            quoted_words.add(f'"{cleaned_name}"')

    output_string = ", ".join(quoted_words)
    formatted_output = insert_linebreaks(output_string)

    if not output_filename.endswith(".txt"):
        output_filename += ".txt"

    try:
        with open(output_filename, 'w', encoding='utf-8') as outfile:
            outfile.write(formatted_output)
        print(f"Processed data saved to '{output_filename}'")
    except Exception as e:
        print(f"Error writing to output file: {e}")

if __name__ == "__main__":
    input_file = input("Enter the input filename: ")
    output_file = input("Enter the output filename: ")
    clean_and_format_names(input_file, output_file)
